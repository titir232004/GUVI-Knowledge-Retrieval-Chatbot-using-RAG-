# ğŸ¤– GUVI Knowledge Retrieval Chatbot ( RAG System)

The **GUVI Knowledge Retrieval Chatbot** is an offline AI assistant built using a **Retrieval-Augmented Generation (RAG)** pipeline.  
It can answer questions using **real GUVI blogs, FAQs, and course information**, all processed, indexed, and queried locally â€” **no API keys, no internet, no external dependencies**.

This project uses:

- **FAISS** for semantic retrieval  
- **Sentence-Transformers** for text embeddings  
- **TinyLlama GGUF** (via llama.cpp) for offline LLM inference  **Download Link:** https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0-GGUF/tree/main
- **Streamlit** for a clean ChatGPT-style chat UI  

---

## âœ¨ Features

- ğŸ” Scrapes and cleans **GUVI Blogs & FAQs**  
- âœ‚ï¸ Splits content into high-quality text chunks  
- ğŸ§  Embeds content using **all-MiniLM-L6-v2**  
- âš¡ Fast similarity search using **FAISS vector DB**  
- ğŸ¤– Offline large language model (TinyLlama) for response generation  
- ğŸ’¬ Beautiful **ChatGPT-style UI** built in Streamlit  
- ğŸ” 100% offline â€” All data stays on your machine  
- ğŸ—‚ï¸ Modular & production-ready code  

---

## ğŸ“ Project Architecture

User Query
â”‚
â–¼
[Streamlit Chat UI]
â”‚
â–¼
[Embedding Model] â†’ Convert query to vector
â”‚
â–¼
[FAISS Vector Store] â†’ Retrieve top-k similar chunks
â”‚
â–¼
[Local LLM (TinyLlama GGUF)]
â”‚
â–¼
Generate final answer based on context
â”‚
â–¼
ChatGPT-style Response to User



---

## âš™ï¸ Requirements

### ğŸ”¹ Python Version  
**Python 3.10+** recommended

### ğŸ”¹ Install Dependencies
After cloning your repo, run:

```bash
pip install -r requirements.txt
